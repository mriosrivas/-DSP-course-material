{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ca5a574d17592110290d753defe276c",
     "grade": false,
     "grade_id": "cell-ac8199f553e8ab39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Rock vs Metal\n",
    "\n",
    "This Jupyter Notebook is inspired in the following papers [Analysis of Hidden Units in a Layered Network\n",
    "Trained to Classify Sonar Targets](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.6963&rep=rep1&type=pdf) and [Learned Classification of Sonar Targets Using a\n",
    "Massively Parallel Network](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.164.2513&rep=rep1&type=pdf) by Paul Gorman and Terrence Sejnowski. In order to complete this project, I highly recommend that you read both papers to fully understand the problems that you will later solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47455331215acb62af03e2c3345de1e8",
     "grade": false,
     "grade_id": "cell-dfa7a1becb568534",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: Create a reflected FM chirp signal\n",
    "A chirp is a signal in which the frequency increases (up-chirp) or decreases (down-chirp) with time. It is commonly applied to sonar, radar, and laser systems, and to other applications, such as in spread-spectrum communications.\n",
    "\n",
    "In spread-spectrum usage, surface acoustic wave (SAW) devices are often used to generate and demodulate the chirped signals. In optics, ultrashort laser pulses also exhibit chirp, which, in optical transmission systems, interacts with the dispersion properties of the materials, increasing or decreasing total pulse dispersion as the signal propagates. The name is a reference to the chirping sound made by birds. \n",
    "\n",
    "In this part two task are described:\n",
    "1. How to create a linear FM swept-frequency cosine chirp signal?\n",
    "2. How to model the received sonar signal? \n",
    "\n",
    "### 1. Mathematical description of the chirp signal\n",
    "This signal is defined as follows:\n",
    "\n",
    "$$x(t)=\\cos{\\left( \\phi(t) + \\rho \\right)}$$\n",
    "\n",
    "where $\\phi(t)$ is the instantaneous phase of the signal given by\n",
    "\n",
    "$$\\phi(t)=\\int_{0}^{t} 2\\pi f(t) dt$$\n",
    "\n",
    "and $f(t)$ as\n",
    "$$f(t) = f_0 + \\frac{(f_1-f_0)t}{t_1}$$\n",
    "\n",
    "where $t_1$ is the chirp's duration, $f_0$ is the initial frequency, and $f_1$ is the frequency at time $t_1$.\n",
    "\n",
    "### 2. Mathematical model of the received chirp signal\n",
    "We can model our received sonar chirp signal $\\hat{x}(t)$ as modified version of the original signal $x(t)$ as follows:\n",
    "\n",
    "suppose we have a transmitted signal\n",
    "\n",
    "$$x(t)=\\cos{\\left( \\phi(t) + \\rho \\right)}$$\n",
    "\n",
    "Which has been affected by three main sources of distortion:\n",
    "1. additive white noise $n(t)$,\n",
    "2. propagation effect, modeled as an exponential decay,\n",
    "3. random time delay $\\tau$ at the receiving end\n",
    "\n",
    "then we can formulate an equation as follows\n",
    "\n",
    "$$\\hat{x}(t)=e^{t}x(t-\\tau)+n(t)$$\n",
    "\n",
    "that describes the received signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47c632368d0577f36c5e3691dd1b173c",
     "grade": false,
     "grade_id": "cell-265bf31c905a79c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Create your python functions\n",
    "In this part you will implement the following two functions:\n",
    "1. `chirp` which is a function that returns a chirp signal like the one described in **Mathematical description of the chirp signal**\n",
    "2. `noisy_chirp` which is a function that returns a signal like the one described in **Mathematical model of the received chirp signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fd93bd6cb25135131cd147319cade78",
     "grade": false,
     "grade_id": "cell-fb635328f6fb3b7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.signal import chirp as scipy_chirp\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d228866913a3c5e5971bc222fb2243ca",
     "grade": false,
     "grade_id": "cell-b5472e5f848afd3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First create your `chirp` function. For this task, you will also create a function `get_phase` which calculates the phase needed for the `chirp` signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26ccf285beca13fd8b957028b1e1ef73",
     "grade": false,
     "grade_id": "cell-d1500082c3e951ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_phase(t, f0, f1, t1):\n",
    "    \"\"\"\n",
    "    Auxiliary function that performs the calculation of the phase of a linear instantaneous frequency.\n",
    "    :param t: (numpy vector) defines the time at which we evaluate the waveform\n",
    "    :param f0: (float) frequency in Hz. at time t=0.\n",
    "    :param f1: (float) frequency in Hz. of the waveform at time t1.\n",
    "    :param t1: (float) time at which f1 is specified\n",
    "    :return: phase calculation of the linear instantaneous phase\n",
    "    \"\"\"\n",
    "    # Implement the instantaneous phase Ï†(t) of a linear signal f(t)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "def chirp(t, f0, f1, t1, phi=0):\n",
    "    \"\"\"\n",
    "    Function that calculates an FM chirp signal.\n",
    "    :param t: (numpy vector) defines the time at which we evaluate the waveform\n",
    "    :param f0: (float) frequency in Hz. at time t=0.\n",
    "    :param f1: (float) frequency in Hz. of the waveform at time t1.\n",
    "    :param t1: (float) time at which f1 is specified\n",
    "    :param phi: (float, optional) Phase offset, in degrees. Default is 0.\n",
    "    :return: (numpy array) chirp FM signal\n",
    "    \"\"\"\n",
    "    # Implement the chirp signal x(t) described before\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a768f2732b7b6123da3662b4fde2a669",
     "grade": false,
     "grade_id": "cell-0e43dbd349009c5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now test your implementation against the SciPy implementation of the chirp signal. If your results match, then everything is working perfectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5600bec075b112413e306fc9cf5ddbb7",
     "grade": true,
     "grade_id": "cell-0964aac224eec88a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "f0 = 1\n",
    "f1 = 6\n",
    "t1 = 100*(1/f1)\n",
    "t = np.linspace(0, t1, 1500)\n",
    "\n",
    "signal_test = chirp(t, f0, f1, t1)\n",
    "signal_reference = scipy_chirp(t, f0=f0, f1=f1, t1=t1, method='linear')\n",
    "\n",
    "match = np.allclose(signal_test, signal_reference)\n",
    "\n",
    "if match:\n",
    "    print(\"Your test and reference signals are same. Gret work!\")\n",
    "else:\n",
    "    print(\"Your test and reference signals differ.\")\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t, signal_test)\n",
    "plt.title(\"Chirp Test Signal\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(t, signal_reference)\n",
    "plt.title(\"Chirp Reference Signal\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "\n",
    "assert match, \"Check your code! Your implementation has some errors!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b30b7fb7c86a9fff960d8d3d3ff7825b",
     "grade": false,
     "grade_id": "cell-22db30b2a9d310c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now make your noisy chirp signal. For this task you will create the `noisy_chirp` function, remember that the function performs the following calculation:\n",
    "\n",
    "$$\\hat{x}(t)=e^{t}x(t-\\tau)+n(t)$$\n",
    "\n",
    "Bear in mind that $\\tau$ introduces an offset to the signal, and at the end of the signal there's also a trailing data received. The following image can explain this idea:\n",
    "\n",
    "![Received](Images/received_signal.png)\n",
    "\n",
    "In order to define your `noisy_chirp` you will have to perform three steps:\n",
    "1. Create a `transmitted` vector that will implement this equation $e^{t}x(t)$.\n",
    "2. Add a header `tau`, a `trail` to the transmitted data. This will simulate the effect of having an offset on the received signal. We will use random values between `50` and `60` for the size of `tau` and `trail`. You can assign the size by using the numpy function `random.randint` to generate random numbers. \n",
    "3. Add noise to the new vector created in step 2, this will simulate the effect of additive noise to the offset signal. Assume noise as a random process with mean zero and standard deviation of `0.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a679ff6d2c00dad6d40e382292e3b46",
     "grade": false,
     "grade_id": "cell-21bf34d09db9d6ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def noisy_chirp(x, t):\n",
    "    \"\"\"\n",
    "    Function that calculates a noisy FM chirp signal. Assume \n",
    "    :param x: (numpy vector) input chirp signal\n",
    "    :param t: (numpy vector) defines the time at which we evaluate the waveform\n",
    "    :return: (numpy array) noisy chirp FM signal\n",
    "    \"\"\"\n",
    "    np.random.seed(123) #Set this to have the same results.\n",
    "    # Step 1:\n",
    "    # Create your transmitted vector\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Step 2:\n",
    "    # Create frame with tau, trail and transmitted\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Step 3:\n",
    "    # Add noise to the received frame\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06c6a48380436a0c11324bc0be090506",
     "grade": true,
     "grade_id": "cell-a9d57f6224a6df61",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('chirp_received.pkl', 'rb') as file:\n",
    "    received_pkl = pickle.load(file)\n",
    "\n",
    "f0 = 13000\n",
    "f1 = 21000\n",
    "t1 = 100*(1/f1)\n",
    "t = np.linspace(0, t1, 120)\n",
    "\n",
    "transmitted = chirp(t, f0, f1, t1)\n",
    "received = noisy_chirp(transmitted, t)\n",
    "\n",
    "assert np.allclose(received, received_pkl, atol=0.01)\n",
    "\n",
    "plt.plot(received)\n",
    "plt.title(\"Noisy Generated Signal\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "119c66165feb0c71552c5bf1a82b57fb",
     "grade": false,
     "grade_id": "cell-c3315e8956285ef6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2: Find the power spectral density\n",
    "Right now our problem is that we want to estimate the power spectral density of a wide-sense stationary random process. The main problem of power spectrum estimation is that data $x[n]$ is always finite. There are two basic approaches to solve this problem:\n",
    "1. Nonparametric such as *Periodogram*, *Bartlett* and *Welch* (most common)\n",
    "2. Parametric approaches (less common)\n",
    "\n",
    "For our implementation we will use Bartlett's method, if you want further information about other methods you can check this [link](http://www.laurent-duval.eu/Documents-Common/Schuster_G_2010_lect_spectrum_upbw.pdf).\n",
    "\n",
    "Bartlettâ€™s method consists of the following steps:\n",
    "\n",
    "1. The original N point data segment is split up into K (non-overlapping) data segments, each of length M\n",
    "2. For each segment, compute the periodogram by the use of the discrete Fourier transform, then compute the squared magnitude of the result and divide this by M.\n",
    "3. Average the result of the periodograms above for the K data segments. (The averaging reduces the variance, compared to the original N point data segment.)\n",
    "\n",
    "The end result is an array of power measurements vs. frequency \"bin\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de49a2cfaaa485c64855b108824ceb87",
     "grade": false,
     "grade_id": "cell-45fabab03e73cd9a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bartlett_periodogram(x, nperseg, fs=1.0):\n",
    "    \"\"\"\n",
    "    Estimate power spectral density using Bartlettâ€™s method.\n",
    "    :param x: (numpy vector) input signal\n",
    "    :param nperseg: (int) length of each segment of data\n",
    "    :param fs: (float) sampling frequency of the x time series. Defaults to 1.0.\n",
    "    :return: freq (numpy vector) normalized frequency values between 0 and 0.5 for psd calculation\n",
    "             psd (numpy vector) power spectral density using Bartlettâ€™s method\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    nsegments = N // nperseg\n",
    "    psd = np.zeros(nperseg)\n",
    "    # Split data into K non-overlapping segments\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    for segment in data_split:\n",
    "        # Use the Fourier Transform on each segment\n",
    "        # Square the magnitude of the Fourier Transform\n",
    "        # Divide by the segment data size\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    psd[0] = 0   # important!!\n",
    "    # Average the psd by the number of data segments\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    psd = psd[0: nperseg // 2] #Removes two sided spectrum\n",
    "    freq = np.linspace(0, fs/2, nperseg//2)\n",
    "    freq /= 2*freq[-1]\n",
    "\n",
    "    return freq, psd #Be cautious to always set psd[0]=0\n",
    "    \n",
    "\n",
    "def fix_size(x, N=64):\n",
    "    \"\"\"\n",
    "    Auxiliary function to give a power of two dimension to input x\n",
    "    :param x: (numpy vector) input signal\n",
    "    :param N: (int) minimum size input x should have\n",
    "    :return: (numpy vector) vector x with size(x)%N zeros appended\n",
    "    \"\"\"\n",
    "    zeros = x.shape[0] % N\n",
    "    if zeros>0:\n",
    "        temp = np.zeros((N-zeros, 1))\n",
    "    return np.append(x, temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d174bd38dccdfb7bd02514a0fa53c610",
     "grade": false,
     "grade_id": "cell-3ef770a47ca31a1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now it is time to test your `bartlett_periodogram` implementation, for this purpose you will compare it with the `signal.welch` from SciPy. The `signal.welch` implementation performs the Welch's method for estimating the spectral density of a signal, since Welch's method is an upgrade version of Bartlett's, we can get the same results for both methods by setting the overlap for Welch's method to zero. You can get more information about Welch's method [here](https://en.wikipedia.org/wiki/Welch%27s_method). Note that Welch returns the power spectral density, which is the power spectrum times $f_s$ and it compensates for cutting away half the spectrum by multiplying with $2$. To compensate, we multiply Bartlett's method by $2f_s$ in order to compare with Welch.\n",
    "Check your results, and if the plots match, then everything works well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a85c9efeb495880734e9d7078dc712",
     "grade": true,
     "grade_id": "cell-ff322d128fe2f4a2",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "nperseg = 64\n",
    "fs = 1\n",
    "\n",
    "f_bartlett, psd_bartlett = bartlett_periodogram(fix_size(received), nperseg=nperseg)\n",
    "\n",
    "f_welch, psd_welch = signal.welch(fix_size(received), fs=fs, nperseg=nperseg, \n",
    "                                nfft=nperseg, window='boxcar', noverlap=0)\n",
    "\n",
    "assert np.allclose(2*fs*psd_bartlett, psd_welch[:-1], atol=0.01)\n",
    "\n",
    "f = f_bartlett\n",
    "\n",
    "plt.plot(f, 2*fs*psd_bartlett, label=\"Custom Implementation\")\n",
    "plt.plot(f, psd_welch[:-1], label=\"SciPy\") \n",
    "plt.title(\"Power Spectral Density\")\n",
    "plt.xlabel(\"Normalized Frequency\")\n",
    "plt.ylabel(\"$V^2Hz$\")\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0a0401b2150e0a428f73ab837d359dc",
     "grade": false,
     "grade_id": "cell-0c4167c2fc8ce9f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 3: Create a classifier using a linear regression model\n",
    "In this final part you will implement a linear regression classifier for the [**Connectionist Bench (Sonar, Mines vs. Rocks) Data Set**](http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)). This dataset is the same used in the papers described at the beginning of this Jupyter Notebook. To simplify our task we are going to use Pandas, which is a data analysis and manipulation library for Python.\n",
    "\n",
    "First we load our dataset which is called `dataset_sonar.csv` and it is stored in the `Dataset` folder. We also defined a function called `get_data` whose purpose is to simplify our data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c36632293ef17bb8cbf8292b09e5d33b",
     "grade": false,
     "grade_id": "cell-831f650592ea9b38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"Dataset/dataset_sonar.csv\"\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "def get_data(data, k):\n",
    "    x = data.iloc[k][0:-1]\n",
    "    y = data.iloc[k][-1]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80ece27d1d9454a487c22a5fabe74cfa",
     "grade": false,
     "grade_id": "cell-3de47aa55e5d39ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here you can see how our data looks and how different a signal from a Rock and Mine is received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "626cef5eccd0de748c93e4441caf1611",
     "grade": false,
     "grade_id": "cell-57a54b1e054ca85d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x0, y0 = get_data(data, k=1)\n",
    "x1, y1 = get_data(data, k=97)\n",
    "t = np.arange(x0.shape[0])\n",
    "\n",
    "plt.plot(t, x0, label=y0)\n",
    "plt.plot(t, x1, label=y1)\n",
    "plt.title(\"Power Spectral Density\")\n",
    "plt.ylabel(\"$V^2Hz$\")\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ab0e4ebf91ba99e33f0c0bc292808ef",
     "grade": false,
     "grade_id": "cell-5344a20c07b6255c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A linear regression model can be described as\n",
    "\n",
    "$$\\hat{y} = w_0 + w_1x_1 + w_2x_2 + \\cdots w_nx_n $$\n",
    "\n",
    "In vector form we can have\n",
    "$$\\hat{y} = Xw $$\n",
    "\n",
    "where $X$ has a column vector of ones in the first entry.\n",
    "\n",
    "The following Python code shows a function called `linear_regression` which is an implementation of a linear regression model. Note that we stack a column of ones to take into account the bias vector $w_0$ from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b879860ed219856668e0762d41570a4",
     "grade": false,
     "grade_id": "cell-31c10703bd209c08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression(X, w):\n",
    "    \"\"\"\n",
    "    Function that calculates a the linear regression model of X and w. \n",
    "    :param X: (numpy matrix) matrix with of features in columns and observations in rows.\n",
    "    :param w: (numpy vector) linear regression coefficients.\n",
    "    :return: (numpy vector) calculation of y = Xw\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    ones = np.ones(n)\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a8c6c85708fa66cd461f15a5976d26a",
     "grade": false,
     "grade_id": "cell-379d9b56547acb50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When we want to find a solution for the equation \n",
    "\n",
    "$$\\hat{y} = Xw $$\n",
    "\n",
    "Usually, this solution is not exact, and instead an approximation using a least squares solution is proposed.\n",
    "\n",
    "We can use the following expession to obtain an approximate estimation of the $w$ coeffcients:\n",
    "$$ y \\approx Xw$$\n",
    "$$ X^Ty \\approx X^TXw$$\n",
    "$$ (X^TX)^{-1}X^Ty \\approx (X^TX)^{-1}(X^TX)w$$\n",
    "$$ (X^TX)^{-1}X^Ty \\approx w$$\n",
    "\n",
    "Where $X^TX$ is called the Gram Matrix\n",
    "\n",
    "\n",
    "We can get better results if we introduce a regularization factor, which reduces the linear relationship between columns, by changing the  in Gram Matrix in the following way:\n",
    "\n",
    "Instead of using a matrix $$X^TX = \\begin{bmatrix}\n",
    "x_{11} & x_{12} & x_{13} & \\cdots & x_{1n} \\\\\n",
    "x_{21} & x_{22} & x_{23} & \\cdots & x_{2n} \\\\\n",
    "x_{31} & x_{32} & x_{33} & \\cdots & x_{3n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{n1} & x_{n2} & x_{n3} & \\cdots & x_{nn}\n",
    "\\end{bmatrix}  $$\n",
    "\n",
    "We use this matrix $$X^TX + \\alpha I = \\begin{bmatrix}\n",
    "x_{11}+\\alpha & x_{12} & x_{13} & \\cdots & x_{1n} \\\\\n",
    "x_{21} & x_{22}+\\alpha & x_{23} & \\cdots & x_{2n} \\\\\n",
    "x_{31} & x_{32} & x_{33}+\\alpha & \\cdots & x_{3n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{n1} & x_{n2} & x_{n3} & \\cdots & x_{nn}+\\alpha\n",
    "\\end{bmatrix}  $$\n",
    "\n",
    "Therefore, our final equation will be\n",
    "\n",
    "$$ (X^TX + \\alpha I)^{-1}X^Ty \\approx w$$\n",
    "\n",
    "\n",
    "Create a function called `train_linear_regression` wich takes as input a matrix `X` of features, a vector `y` of labels and a regularization factor `r`. This function trains a linear regression model using the equation described before. You can use the `np.dot` funtion to multiply two matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05184b59e9d5d04712bd820fc969238b",
     "grade": false,
     "grade_id": "cell-7acb839c491d78da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_linear_regression(X, y, r=1):\n",
    "    \"\"\"\n",
    "    Function that estimates the linear regression coefficients using a least squares solution. \n",
    "    :param X: (numpy matrix) matrix with of features in columns and observations in rows.\n",
    "    :param y: (numpy vector) expected values.\n",
    "    :return: (numpy vector) estimated w coefficients\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    ones = np.ones(n)\n",
    "    # Add an extra column to X to add the bias term of the linear regression\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Implement the equation for approximating the w values \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "684e3089fe62e64afefae3d58e3cb588",
     "grade": false,
     "grade_id": "cell-41a017c631882d0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this test you will see if your `train_linear_regression` function works correctly. Your expected mean squared error should be around `0.0009`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0c65da17b54b990eaadb2352cf3e993",
     "grade": true,
     "grade_id": "cell-ed59c56dde46909f",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, -1, 2], [-3, -5, 4], [6, -7, -8]])\n",
    "y = np.array([[ -7], [-27], [ 22]])\n",
    "\n",
    "w_hat = train_linear_regression(X, y, r=0.1)\n",
    "\n",
    "y_hat = linear_regression(X, w_hat)\n",
    "\n",
    "mse = np.mean((y - y_hat)**2)\n",
    "\n",
    "with open('y_hat.pkl', 'rb') as file:\n",
    "    y_hat_pkl = pickle.load(file)\n",
    "    \n",
    "assert np.allclose(y_hat, y_hat_pkl, atol=0.01)\n",
    "\n",
    "print(f'Exected value = \\n {y} \\n \\n Predicted value = \\n {y_hat} \\n')\n",
    "print(f'MSE = {mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97d17cda5b8a83401655071b1415360d",
     "grade": false,
     "grade_id": "cell-80ffc4dd6248a38e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that you've created your linear model, and tested that correctly estimates the coefficients,  we can use it to classify our data into rock and metal. Usually we split all of our data into three groups:\n",
    "* Training data: used for training the model\n",
    "* Validation data: used for selecting best parameters\n",
    "* Test data: used for evaluating the performance of the model\n",
    "\n",
    "For this task, a `split_data` function is provided, where you include a pandas dataframe as input `df`, and set the proportion of data used for validation `val_proportion`, and the data used for testing `test_proportion`. A good rule of thumb is to use a `0.20` proportion for both validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2d1305eef6384e6ee4cd49969d2bbc9",
     "grade": false,
     "grade_id": "cell-b7b96a6163594c62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def split_data(df, val_proportion=0.30, test_proportion=0.30, random_seed=True):\n",
    "    \"\"\"\n",
    "    Auxiliary function to split data into training, validation and test data.\n",
    "    :param df: (pandas dataframe) dataframe with features to train the model.\n",
    "    :param val_proportion: (float) value between 0 and 1 to set the proportion of validation data.\n",
    "    :param test_proportion: (float) value between 0 and 1 to set the proportion of test data.\n",
    "    :return: (tuple) tumple containing df_train, df_val, df_test dataframes\n",
    "    \n",
    "    \"\"\"\n",
    "    if random_seed:\n",
    "        np.random.seed(2)\n",
    "        \n",
    "    n = len(df)\n",
    "    n_val = int(n * val_proportion)\n",
    "    n_test = int(n * test_proportion)\n",
    "    n_train = n - (n_val + n_test)\n",
    "\n",
    "    # Create a list of indices and shuffle them\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    # Sample from the shuffled indices\n",
    "    N_train = idx[:n_train]\n",
    "    N_val = idx[n_train:n_train + n_val]\n",
    "    N_test = idx[n_train + n_val:]\n",
    "    len(N_train), len(N_val), len(N_test)\n",
    "\n",
    "    df_train = df.iloc[N_train]\n",
    "    df_val = df.iloc[N_val]\n",
    "    df_test = df.iloc[N_test]\n",
    "    \n",
    "    # Reset the index of every dataframe\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    \n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "383f1e7c8eed69c10599e7b9d44fa06b",
     "grade": false,
     "grade_id": "cell-70b29dfd4ade5c85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set val_p and test_p to the typical values used as rule of thumb.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "df_train, df_val, df_test = split_data(data, val_proportion=val_p, test_proportion=test_p, random_seed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebaeedc3169dcb5d8fc9253f972abb64",
     "grade": true,
     "grade_id": "cell-fc05dce63ea6ac17",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_train.shape == (126, 61)\n",
    "assert df_val.shape == (41, 61)\n",
    "assert df_test.shape == (41, 61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f01344051111f2778ff44fb95cdc9578",
     "grade": false,
     "grade_id": "cell-97e80f6f9a1e327b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since we are not going to select the best parameters for our model, we will merge the training and validation data into a full data set called `df_full_train`. Therefore, we will be using a training and test set for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00e9fbb00dc94b32902caa9c48b6ff91",
     "grade": false,
     "grade_id": "cell-0d93e7a3dcaa3371",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a full training set\n",
    "df_full_train = pd.concat([df_train, df_val]).reset_index(drop=True)\n",
    "\n",
    "# Training Data\n",
    "X_full_train = df_full_train.iloc[: , :-1].values\n",
    "Y_full_train = (df_full_train.iloc[:, -1] == 'Rock').astype('int')\n",
    "\n",
    "# Test Data\n",
    "X_test = df_test.iloc[: , :-1].values\n",
    "Y_test = (df_test.iloc[:, -1] == 'Rock').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de72d4426ddc9221d27aff01a33ede02",
     "grade": false,
     "grade_id": "cell-db2edda8e3052c77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Use your linear regression model to estimate the vector W\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Predict y_hat the linear_regression function \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75fde1c5951dec99c20c87b697a3e4ff",
     "grade": true,
     "grade_id": "cell-b9c5f3c1332b23fc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = sum((Y_hat>0.50).astype('int') == Y_test)/Y_test.shape[0]\n",
    "\n",
    "# Compare against the RidgeClassifier from Scikit-learn\n",
    "clf = RidgeClassifier()\n",
    "clf.fit(X_full_train, Y_full_train)\n",
    "\n",
    "accuracy_ridge_classifier = sum(clf.predict(X_test) == Y_test)/Y_test.shape[0]\n",
    "\n",
    "assert np.isclose(accuracy, accuracy_ridge_classifier, atol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0767ff02a2e333f6b4ab7182fd7d4b11",
     "grade": false,
     "grade_id": "cell-5ae35dfdf4d57283",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 4: Questions\n",
    "* Why do we use the power spectral density in our linear classifier instead of the time domain signal?\n",
    "* What does regularization mean, and why do we use it in our linear classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f5f05df52518afed0e214dade8016e1",
     "grade": true,
     "grade_id": "cell-2fea656d151b9f94",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
