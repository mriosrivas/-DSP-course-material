{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b33312bea8b5455e6853e7d15274d61e",
     "grade": false,
     "grade_id": "cell-d4a6930ffd26352a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# LMS filter and ADALINE algorithm\n",
    "\n",
    "<font color=\"blue\">Note: In order to run this Jupyter Notebook you must create a file named `aux_functions.py` inside the folder containing this Notebook with a function named `get_fourier` developed previously.</font> \n",
    "\n",
    "In this first project you will implement a Least Mean Square (LMS) error filter by using the Adaptive Linear Neuron (ADALINE) algorithm. This algorithm is a class of adaptive filter used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square of the error signal (difference between the desired and the actual signal). It is a stochastic gradient descent method in that the filter is only adapted based on the error at the current time. It was invented in 1960 by Stanford University professor Bernard Widrow and his first Ph.D. student, Ted Hoff.\n",
    "\n",
    "To fully understand the concepts of this filter I recommend you to watch the following lecture by professor Widrow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce4e2a885f86f682c503d575398cd486",
     "grade": false,
     "grade_id": "cell-aaa0dcb1883d61c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from aux_functions import get_fourier\n",
    "from aux_plots import plot_frequency_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a17a88f3f37bce48d529dbbcb10c166",
     "grade": false,
     "grade_id": "cell-c7820f0b6f27e9d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" \\\\\\\n",
    "     src=\"https://www.youtube.com/embed/hc2Zj55j1zU\" \\\\\\\n",
    "     title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; \\\\\\\n",
    "     autoplay; clipboard-write; encrypted-media; \\\\\\\n",
    "     gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "801c34a0c2ccb534068c8968a7ca9072",
     "grade": false,
     "grade_id": "cell-7cdc17152e7d2cbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After watching professor Widrow's lecture, you can also take a look at [this paper](https://isl.stanford.edu/~widrow/papers/j1975thecomplex.pdf) to fully understand the LMS filter and ADALINE algorithm. A good summary on how the algorithm works is presented in section 2 of [this page](https://www.clear.rice.edu/elec422/1999/nsekila/LMSAlgorithm.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e4b7dd137feb96960ddbfdb4738d2fc",
     "grade": false,
     "grade_id": "cell-f164ce4f71565984",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem: Implement a LMS filter and ADALINE algorithm to find the coefficients of a Digital Filter\n",
    "The main problem of this project is to implement the LMS filter and ADALINE algorithm to obtain the coefficients of a filter response $w[n]$ given the input $x[n]$ and the convolution $y[n] = x[n]*w[n]$. Since this is a supervised machine learning algorithm, you will train your model with a buffered version of the input $x[n]$ and compare your calculations with the expected outputs $y[n]$. After many iterations, you will notice that the coefficients tend to converge to the desired ones of the filter while reducing the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2aab044725c7c2073f259a3a4a120cae",
     "grade": false,
     "grade_id": "cell-8cbba12e205d7266",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: Defining the Algorithm\n",
    "In this first part you will have to create a block diagram of the LMS filter and ADALINE algorithm based on the information given to you in the previous section, to do so, you can use any available tool that you want to create your block diagram as a png image.\n",
    "\n",
    "\n",
    "Your image should be called `algorithm.png` and be saved in the folder `Images`. You can instantiate your image by adding the following code on the next block of code of this Jupyter Notebook:\n",
    "\n",
    "``` html\n",
    "<img src=\"Images/algorithm.png\" alt=\"Block Diagram\" width=\"300\"/>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b80c28a18aeb5fabeac7932a7307a1f",
     "grade": true,
     "grade_id": "cell-fd24a21ead4f3ddc",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29e127a68caf6ceedee60000b8b5fa9e",
     "grade": false,
     "grade_id": "cell-11dff911341a8e22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2: Create a buffer of streamed data\n",
    "To understand how data is processed by the filter you need to think about a buffer $Z$ that will be filled with some input data. First suppose that your buffer is of size 5 and is completely empty, for example full of zeros, and you have a vector $x$ also of size 5 with some data. Now let's see Figure 1 and understand what happens on every time step.\n",
    "\n",
    "<img src=\"Images/buffer.png\" alt=\"buffer\" width=\"300\"/>\n",
    "\n",
    "You can see that the data inside of $Z$ is moved and there are two special cases:\n",
    "1. Data inside $Z$ is fully loaded (green color).\n",
    "2. Data inside $Z$ is loaded and emptied (orange and green colors)\n",
    "\n",
    "With this image in mind, you can think that a filter processes a chunk of data given by the buffer on a specific time step instead of a recursive manner. This way you have a training data for a period of time that can be used in our LMS filter and ADALINE algorithm.\n",
    "\n",
    "Now it is your turn to create a function called `get_buffer` that generates a buffer matrix $Z$. This buffer matrix can be in fully loaded or a loaded and emptied form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6316e3b7c63830d3396f496847dbddf0",
     "grade": false,
     "grade_id": "cell-a3737625fea4dfa3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f47e12c328646a88efa3e1b5c0f650d6",
     "grade": false,
     "grade_id": "cell-ea5af5501a79c2fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_buffer(x, buffer_size=5, form='fl'):\n",
    "    \"\"\"\n",
    "    Function that generates a buffer matrix with a fully loaded or loaded and emptied form.\n",
    "    Parameters: \n",
    "    x (numpy array): Array of numbers representing the input signal.\n",
    "    buffer_size (int): Size of buffer.\n",
    "    form (string): String that represent the form of the Z matrix. \n",
    "                   Can be 'fl' for fully loaded or 'lae' for loaded and emptied.\n",
    "                   By default fully loaded is selected.\n",
    "  \n",
    "    Returns: \n",
    "    Z (numpy array): Matrix with a fully loaded or loaded and emptied form.\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2ee7507e70554b672953164bcb6b877",
     "grade": false,
     "grade_id": "cell-0536b069e8cd27fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now test your `get_buffer` function with the following code and check if it matches your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cd1edecdc52dfec47af924b6eefd9da",
     "grade": true,
     "grade_id": "cell-f1746082cfc0acb3",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('buffer_data.pkl', 'rb') as file:\n",
    "    buffer_fl_pkl, buffer_lae_pkl = pickle.load(file)\n",
    "\n",
    "test = np.arange(0,16)\n",
    "\n",
    "buffer_fl = get_buffer(test, buffer_size=8, form='fl')\n",
    "buffer_lae = get_buffer(test, buffer_size=4, form='lae')\n",
    "\n",
    "print(\"Fully Loaded Form\")\n",
    "print(buffer_fl, \"\\n\")\n",
    "print(\"Loaded and Emptied Form\")\n",
    "print(buffer_lae)\n",
    "\n",
    "assert np.allclose(buffer_fl, buffer_fl_pkl)\n",
    "assert np.allclose(buffer_lae, buffer_lae_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef6c23f21fb7a5e513516030308dfabf",
     "grade": false,
     "grade_id": "cell-e7f88a4e1444c5fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 3: Implement convolution\n",
    "Now that you have a way to represent a vector $x$ as a buffer matrix $Z$ you will have to use it to implement a convolution as a matrix product between $Z$ and $w$, where $w$ is a vector of the coefficients of a filter response.\n",
    "\n",
    "Your results should match the usage of the `numpy` function `convolve` as follows:\n",
    "1. When using $Z_{lae}$ results should match `np.convolve(x, w, mode='full')`.\n",
    "2. When using $Z_{fl}$ results should match `np.convolve(x, w, mode='full')[0:-w.shape[0]+1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5ac61f682c7f6bf6dcf602c35a93920",
     "grade": false,
     "grade_id": "cell-f48afeacc62f34aa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([-5, 1, -3, 2, 4, 0, 1, -7, 9, 3, -5, -6, 8, 4, 3, 0, 1, -4])\n",
    "w = np.array([7, -3, 1, 4, -9, -2])\n",
    "\n",
    "# Implement your Z_lae calculation\n",
    "# Add your first test here: \n",
    "# Compare your get_buffer implementation and the np.convolve implementation\n",
    "# Assign to conv_lae your implementation\n",
    "# Assign to numpy_conv_lae the numpy implementation\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4c9ca1639022c05b7d2bc4cc73de80a",
     "grade": true,
     "grade_id": "cell-180d4eac9e892dff",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(conv_lae, numpy_conv_lae)\n",
    "print(\"Convolution using Z_lea \\n {}\".format(conv_lae))\n",
    "print(\"Convolution using numpy_lea \\n {}\".format(numpy_conv_lae))\n",
    "print(\"Comparison using Z_lea and numpy is same?: {} \\n\".format((conv_lae==numpy_conv_lae).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e275d569a0bf34f741f42b4e2aecaf9d",
     "grade": false,
     "grade_id": "cell-f1b0b02cd4b35b6c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement your Z_fl calculation\n",
    "# Add your second test here:\n",
    "# Compare your get_buffer implementation and the np.convolve implementation\n",
    "# Assign to conv_fl your implementation\n",
    "# Assign to numpy_conv_fl the numpy implementation\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19207a14dac4dc3af4663e690604c2fb",
     "grade": true,
     "grade_id": "cell-f0b0fd9abcda5fb5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(conv_fl, numpy_conv_fl)\n",
    "print(\"Convolution using Z_fl \\n {}\".format(conv_fl))\n",
    "print(\"Convolution using numpy_fl \\n {}\".format(numpy_conv_fl))\n",
    "print(\"Comparison using Z_fl and numpy is same?: {}\".format((conv_fl==numpy_conv_fl).all()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37dcf8a81a856a35c9b87ae79e54f3f2",
     "grade": false,
     "grade_id": "cell-9678d8d7e24dbea8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 4: Implement LMS filter and ADALINE algorithm\n",
    "Now it is time to implement your LMS filter and ADALINE algorithm, in order to do so you need to create a function called `adaline_filter` which takes as arguments the following values:\n",
    "* `X` which is a matrix in fully loaded or loaded and emptied form.\n",
    "* `w` an initial vector for the estimated filter.\n",
    "* `y_hat` the expected output vector for the filter, sometimes called ground truth.\n",
    "* `alpha` is the learning rate or convergence factor (step size).\n",
    "* `epochs` is the number of iterations.\n",
    "\n",
    "As outputs you will have:\n",
    "* `w` which is an updated version of the initial input vector $w$.\n",
    "* `loss` is an array vector that stores the mean square error loss function, MSE, for every epoch or iteration, you can read more about the MSE loss function [here](https://en.wikipedia.org/wiki/Mean_squared_error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3f5091bfc3243683c068a75faebf0f0",
     "grade": false,
     "grade_id": "cell-c900870a1fcb8953",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def adaline_filter(X, w, y_hat, alpha=0.0005, epochs=100):\n",
    "    \"\"\"\n",
    "    Function that generates a buffer matrix with a fully loaded or loaded and emptied form.\n",
    "    Parameters: \n",
    "    X (numpy array): Matrix in fully loaded or loaded and emptied form.\n",
    "    w (numpy array): Initial vector for the estimated filter.\n",
    "    y_hat (numpy array): Expected output vector for the filter, sometimes called ground truth.\n",
    "    alpha (float): Learning rate or convergence factor (step size).\n",
    "    epochs (int): Number of iterations.\n",
    "    \n",
    "    Returns:\n",
    "    w (numpy array): Updated version of the initial input vector w.\n",
    "    loss (numpy array): Array vector that stores the mean square error loss function for every\n",
    "                        epoch or iteration.\n",
    "    \"\"\"\n",
    "    loss = []\n",
    "    for i in range(epochs):\n",
    "        # Filter\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Error and loss estimation\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        # Gradient calculation\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Update\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8acdcda7722a4849ad86d2e604aa999",
     "grade": false,
     "grade_id": "cell-bb2204c82c4f46fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To test your algorithm an input vector `x` and the ground truth vector `y_hat` are given, you will have to estimate your `w_est` vector using the `adaline_filter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27d81060f31945740d9d600b5346a4ab",
     "grade": false,
     "grade_id": "cell-8d24dd2b543318de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2, -3, 4, -6, 2, 4, -1, 7, 4, 8, 6, -1, 0, 3, -9, -7])\n",
    "y_hat = np.array([4, 10, -7, 9, -23, 13, -4, 32, 12, 21, 58, 21, 18, -12, 9, -15, -45, -32, 26, 3, -14])\n",
    "\n",
    "# Estimate your variable w_est using the adaline_filter developed before\n",
    "# Remember to initialize your w vector before applying the adaline_filter.\n",
    "# Set your initial vector w = [0, 0, 0, 0, 0]\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "214b947cc7671e834eee53e54162dc78",
     "grade": true,
     "grade_id": "cell-255cce1fc41ddb6b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Ground truth\n",
    "w_hat = np.array([4, 2, 1, -3, 2])\n",
    "assert np.allclose(w_est, w_hat)\n",
    "print(\"Estimated w values are: {}\".format(w_est))\n",
    "\n",
    "plt.plot(loss_mse, label=\"Learning = 0.0005\")\n",
    "plt.title(\"MSE Loss vs. Iteration\");\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b34074040695638704fc5981f98e86e3",
     "grade": false,
     "grade_id": "cell-0d5d0f94aaa3ee84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 5: Plot Results with Different Learning Rates\n",
    "In this part you will compare and plot your results by using three different learning rates `alpha` and `epochs = 200` in the same figure. For this, you need to use the following values:\n",
    "* `alpha = 0.0002`\n",
    "* `alpha = 0.0005`\n",
    "* `alpha = 0.00006`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3de52983b12ffc729b8520f999d61333",
     "grade": false,
     "grade_id": "cell-607606a1f1386141",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# With alpha=0.0002 assign your adaline_filter results to:\n",
    "# w1 -> weight\n",
    "# loss1 -> loss\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# With alpha=0.0005 assign your adaline_filter results to:\n",
    "# w2 -> weight\n",
    "# loss2 -> loss\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# With alpha=0.00006 assign your adaline_filter results to:\n",
    "# w3 -> weight\n",
    "# loss3 -> loss\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9e97e04545308a49bce9419b40a6775",
     "grade": true,
     "grade_id": "cell-4bbf8f8342f3de18",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('results.pkl', 'rb') as file:\n",
    "    w1_pkl, loss1_pkl, w2_pkl, loss2_pkl, w3_pkl, loss3_pkl = pickle.load(file)\n",
    "    \n",
    "assert np.allclose(w1_pkl, w1, atol=0.01)\n",
    "assert np.allclose(loss1_pkl, loss1, atol=0.01)\n",
    "assert np.allclose(w2_pkl, w2, atol=0.01)\n",
    "assert np.allclose(loss2_pkl, loss2, atol=0.01)\n",
    "assert np.allclose(w3_pkl, w3, atol=0.01)\n",
    "assert np.allclose(loss3_pkl, loss3, atol=0.01)\n",
    "\n",
    "plt.plot(loss1, label=\"Learning = 0.0002\");\n",
    "plt.plot(loss2, label=\"Learning = 0.0005\");\n",
    "plt.plot(loss3, label=\"Learning = 0.00006\");\n",
    "plt.title(\"MSE Loss vs. Iteration\");\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bed96d4ded3f9b5b80861e68190a5459",
     "grade": false,
     "grade_id": "cell-8e13c6f7f1596944",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 6: Apply your LMS filter and ADALINE algorithm\n",
    "In this part you will use your algorithm to find the coefficients of a filter based on the expected results of the output. \n",
    "For this problem an input signal with three different tones of $30, 50$ and $150Hz$ is sampled at $800Hz$, added to the input signal there's also noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23031016628f4b4edac736c81df35ba3",
     "grade": false,
     "grade_id": "cell-9420561990cf38ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Signal Generation\n",
    "\n",
    "# Create a tone with frequency fc_1 of 50 Hz\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create a tone with frequency fc_2 of 150 Hz\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create a tone with frequency fc_3 of 30 Hz\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Set a sample frequency fs of 400 Hz\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# We set the time window\n",
    "Ts = 1/fs\n",
    "t = np.arange(0,0.10,Ts)\n",
    "\n",
    "# We create three different signals\n",
    "signal_1 = np.sin(2*np.pi*fc_1*t)\n",
    "signal_2 = np.sin(2*np.pi*fc_2*t)\n",
    "signal_3 = np.sin(2*np.pi*fc_3*t)\n",
    "\n",
    "# We create a random noise signal that will be added to our model\n",
    "np.random.seed(123)\n",
    "noise = np.random.rand(signal_1.shape[0])\n",
    "\n",
    "# Create an input signal x wich is the sum of the three signals and the noise\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Our expected output signal will be the sum of signal_1, signal_2 and some extra noise\n",
    "# Note that this extra noise is not the same as the one used above.\n",
    "# Assign to y_hat the expected signal.\n",
    "# Use a random signal with seed equal to 42.\n",
    "np.random.seed(42)\n",
    "noise_hat = np.random.rand(signal_1.shape[0])\n",
    "y_hat = signal_1 + signal_2 + noise_hat\n",
    "\n",
    "plt.plot(x);\n",
    "plt.stem(x, use_line_collection=True);\n",
    "plt.title(\"Input Signal\");\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"amplitude\")\n",
    "plt.grid(\"on\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdaa68f858247d3abfb2698dde2b091d",
     "grade": true,
     "grade_id": "cell-9522b76227bb6d61",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('signal_test.pkl', 'rb') as file:\n",
    "    x_pkl, y_hat_pkl = pickle.load(file)\n",
    "\n",
    "assert np.allclose(x, x_pkl, atol=0.01)\n",
    "assert np.allclose(y_hat, y_hat_pkl, atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0b90d684b4dca02d940402198cb26e7",
     "grade": false,
     "grade_id": "cell-2cf242f85f668391",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this part you will use a for loop to find the filter coeffients `w` using your `adaline_filter` function. For this, you will use the signal `x` and `y_hat` from the previous part. The for loop in here will evaluate with two different number of epochs: `2` and `200`. The filter coefficents `w` will be stored in a dictionary named `W`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1627de4f27c714b02039188189070f8",
     "grade": false,
     "grade_id": "cell-da582e03c0ab86c0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set an empty dictionary and name it W\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "for e in [2, 200]:\n",
    "    # We will assume that our filter coefficients are a total of 51\n",
    "    # Initialize the filter coefficients w by setting them to zero\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Find the filter coefficients w using the adaline_filter function\n",
    "    # Use a fl form for the get_buffer function\n",
    "    # Use a value of alpha of 0.0005\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    W [f'epochs={e}'] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59b09a4f03a01f19baf470d11f5de7de",
     "grade": true,
     "grade_id": "cell-915a3ce676c46622",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('epochs.pkl', 'rb') as file:\n",
    "    W_pkl = pickle.load(file)\n",
    "\n",
    "assert np.allclose(W_pkl['epochs=2'], W['epochs=2'], atol=0.01)\n",
    "assert np.allclose(W_pkl['epochs=200'], W['epochs=200'], atol=0.01)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "conv = np.convolve(x, W['epochs=2'], mode='full')\n",
    "plt.plot(conv/conv.max(), label=\"Estimate\");\n",
    "plt.plot(y_hat/y_hat.max(), label=\"Expected\");\n",
    "plt.title(\"Comparison between convolutions\");\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "conv = np.convolve(x, W['epochs=200'], mode='full')\n",
    "plt.plot(conv/conv.max(), label=\"Estimate\");\n",
    "plt.plot(y_hat/y_hat.max(), label=\"Expected\");\n",
    "plt.title(\"Comparison between convolutions\");\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "W_, f_ = get_fourier(W['epochs=2'])\n",
    "plot_frequency_response(W_.reshape(-1,1), f_*fs)\n",
    "plt.vlines(x=fc_1, ymin=-50, ymax=10, color='red', linestyles='--')\n",
    "plt.vlines(x=fc_2, ymin=-50, ymax=10, color='red', linestyles='--')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "W_, f_ = get_fourier(W['epochs=200'])\n",
    "plot_frequency_response(W_.reshape(-1,1), f_*fs)\n",
    "plt.vlines(x=fc_1, ymin=-50, ymax=10, color='red', linestyles='--')\n",
    "plt.vlines(x=fc_2, ymin=-50, ymax=10, color='red', linestyles='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2423829a0703e0a7dd06df1be67c702b",
     "grade": false,
     "grade_id": "cell-5ecea2907b4e6781",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 7: Questions\n",
    "* What does overfitting mean?\n",
    "* What happens with the frequency and time results when you overfit your ADALINE filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8aa706f884c9c6283d97ce11bba41a2e",
     "grade": true,
     "grade_id": "cell-32e111448727c4e8",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
